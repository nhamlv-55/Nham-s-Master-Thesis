\section{Symbolic Model Checking using co-occurrence probabilities}
In the automated reasoning domain, we introduce \dpy, a neural-based Symbolic Model Checker (SMC) / Constraint Horn Clauses (CHC) Solver.

Model checking has been widely used in various important areas such as robustness analysis of deep neural networks~\cite{Katz:cav19}, verification of hardware designs~\cite{SMC96}, software verification~\cite{Ball02}, analysis~\cite{ESC-java-02} and testing~\cite{Sheyner:SP02}, parameter synthesis in biology~\cite{Barnat:biology12}, and many others. 
The central challenge of model checking is to find a concise and sound approximation of all possible states a given system may reach, which does not cover any undesired states (i.e. violating given specifications). 
Tremendous processes have been made by innovations in efficient data representations~\cite{BDD}, scalable SAT solvers~\cite{CDCL,chaff,minisat}, and effective heuristics~\cite{CEGAR,BMC,McMillan:cav06}.  
Modern model checkers share a common basis, namely, IC3~\cite{IC3}, of which the key insight is \textit{inductive generalization (inductive generalization)}.
This idea has been generalized to support rich theories~\cite{GPDR} that are crucial for many verification tasks~\cite{Komuravelli:cav13,SeaHorn} beyond hardware verification. 
The generalized IC3 with rich theories, also known as satisfiability checking for Constrained Horn Clauses modulo Theory
(CHC)~\cite{DBLP:conf/birthday/BjornerGMR15}, becomes the core part of a broad range of verification tasks.


% \NL{essentially it is a search problem, and traditionally handcrafted heuristics are used. ML can give better heuristic blabh blah}
% With deep learning models being applied in many real life application, verifying them is very important, and push traditional model checking methods to its boundary.

Existing inductive generalization techniques follow either an enumerative search process \cite{IC3,Bradley:fmcad11} or ad-hoc heuristics \cite{Griggio:CAD16,GSpacer}. 
Heuristics are effective but may demand non-trivial domain-specific (or even problem-specific) expertise. 
In this work, we aim to automatically learn such heuristics from the past successful inductive generalizations. 
We observe that verification problems as well as associated inductive generalizations are not isolated from each other. 
Taking software verification as an example, verifying different properties of the same program involves similar or same inductive generalizations; different versions of programs have similar code base; and
different software may use same coding convention, idioms, library or framework, resulting in similar structures.


% Can inductive generalization heuristics be automatically learned?
% Our approach is inspired by the recent advances in deep learning, which automatically learn non-trivial patterns from raw pixels~\cite{Krizhevsky:nips12} as well as semantic correlations between natural language texts~\cite{Mikolov:nips13}.
A natural solution is to train a deep learning model to directly perform inductive generalization, but this approach also raises many new challenges for deep learning. 
% symbols, 
% structured data,
% semantic reasoning (semantic valid/correct), 
% soundness,
% training data.
First of all, the input and the output of inductive generalization are symbolic expressions, which are \textit{highly structured} with \textit{rich semantics}. 
Slight syntactic variations can lead to dramatic changes in semantics.
Second, more importantly, inductive generalization has to satisfy complicated \textit{semantic constraints}. 
Third, given deep learning models hardly provide any reliable guarantees, how to design a neuro-symbolic system that exhibits \textit{learnability} from past experiences but still preserves \textit{soundness}?
% Fourth, how to learn a neural model through a sequence of complicated logical reasoning which are clearly \textit{not differentiable}?
All these challenges have to be properly addressed in building a neuro-symbolic reasoning framework. 
% In this work, we share our design choices and empirical findings in building 

In \cref{chap:dopey}, we present a neuro-symbolic engine \dpy, which introduces a neural component into symbolic model checking. Specifically, we make the following contributions: 
\begin{itemize}
    % \item we study the performance bottleneck of symbolic model checking and
    % factor out a component that are suitable for learning from the past runs;
    \item we adapt standard deep learning models to effectively represent symbolic expressions by incorporating both syntactic and semantic information;
    \item we design a simple but effective learning objective so that training data can be collected with nearly no changes of existing model checkers; 
    \item our integration algorithm achieves the soundness by design, and in the worst case, the learning component may only hurt the running time performance; 
    \item we implement \dpy on top of \spc, a state-of-the-art CHC-solver, using an efficient client-server architecture;
    \item our empirical evaluations indicate \dpy significantly improves \spc on 
    challenging benchmarks from \chccomp.
\end{itemize}
