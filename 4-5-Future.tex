\section{Related work and Conclusions}\label{sec:future}
%\subsection{Related work}
%\paragraph{Compiler optimization using Machine learning}

% \paragraph{Related work}
Recent advances in deep learning and RL have opened new frontiers to the design
of compiler heuristics~\cite{autotuning}. Most current approaches define actions
at the compilation unit level: whether to run a particular optimization pass, or
how to schedule optimization passes. For example, Cummins et al.~\cite{deeptune}
model code as a natural language problem to predict whether to run the code on
CPU or GPU, as well as the optimal GPU thread coarsening factors. Kulkarni et
al.~\cite{KulkarniCWS13} use NEAT --- a genetic algorithm --- to learn an
inlining heuristic for MaxineVM as a neural network. For interpretability, they
then approximate the neural network by a decision tree. We, on the other hand,
use actions at much lower granularity, focusing on specialization at each
call-site.
% Moreover, they do not model the compilation process as a Markov Decision
% Process.

Program code is a rich structure that can be presented in a variety of ways,
e.g., as raw text, control-flow and call- graphs, etc. Recent application of
deep learning for code experiment with models based on techniques from Natural
Language Processing and Graph Neural Network (e.g.,~\cite{code2vec, inst2vec,
  code2seq, code2blah}). Among them, \insttovec~\cite{inst2vec} is the only one
that works on LLVM IR. %Applying \insttovec to \occam was therefore a natural
%choice for us.

The closest related work is Chisel~\cite{chisel} -- a software debloater based
on RL. Inspired by C-Reduce~\cite{creduce}, Chisel takes a program $P$ and a
property of interest $\varphi$ (i.e., $P$ must compile and pass tests defining
$\varphi$) and produces the smallest program $P'$ that satisfies $\varphi$. RL
accelerates the search for the reduced program providing a scalability boost.
Compared to \doccam, Chisel has very different state and action space, and, is generally
only as sound as the test cases defining $\varphi$.
\paragraph{Conclusions}
In this thesis, we present \doccam --- an end-to-end tool to learn
specialization heuristics for software debloating. Our preliminary results
suggest that it is feasible to use RL to learn an effective specialization
heuristic to optimize a variety of related metrics. They also suggest that out
of the box, pretrained embedding such as \insttovec might not be applicable for the task.

We hope that \doccam contributions in feature engineering and architecture
might be applicable to other compiler optimization tasks such as inlining.

This chapter is adapted from the following published work:
\begin{itemize}
    \item Nham Le, Ashish Gehani, Arie Gurfinkel, Susmit Jha, Jorge A.Navas, \textit{Reinforcement Learning Guided Software Debloating}, Workshop on ML for Systems at NeurIPS 2019
\end{itemize}
