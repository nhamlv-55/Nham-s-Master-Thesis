@article{universal,
title = "Multilayer feedforward networks are universal approximators",
journal = "Neural Networks",
volume = "2",
number = "5",
pages = "359 - 366",
year = "1989",
issn = "0893-6080",
doi = "https://doi.org/10.1016/0893-6080(89)90020-8",
url = "http://www.sciencedirect.com/science/article/pii/0893608089900208",
author = "Kurt Hornik and Maxwell Stinchcombe and Halbert White",
keywords = "Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks",
abstract = "This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators."
}
@article{neuralsat,
  author    = {Daniel Selsam and
               Matthew Lamm and
               Benedikt B{\"{u}}nz and
               Percy Liang and
               Leonardo de Moura and
               David L. Dill},
  title     = {Learning a {SAT} Solver from Single-Bit Supervision},
  journal   = {CoRR},
  volume    = {abs/1802.03685},
  year      = {2018},
  url       = {http://arxiv.org/abs/1802.03685},
  archivePrefix = {arXiv},
  eprint    = {1802.03685},
  timestamp = {Mon, 13 Aug 2018 16:47:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1802-03685.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{elmo,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@article{drug_dis,
title = "The rise of deep learning in drug discovery",
journal = "Drug Discovery Today",
volume = "23",
number = "6",
pages = "1241 - 1250",
year = "2018",
issn = "1359-6446",
doi = "https://doi.org/10.1016/j.drudis.2018.01.039",
url = "http://www.sciencedirect.com/science/article/pii/S1359644617303598",
author = "Hongming Chen and Ola Engkvist and Yinhai Wang and Marcus Olivecrona and Thomas Blaschke",
abstract = "Over the past decade, deep learning has achieved remarkable success in various artificial intelligence research areas. Evolved from the previous research on artificial neural networks, this technology has shown superior performance to other machine learning algorithms in areas such as image and voice recognition, natural language processing, among others. The first wave of applications of deep learning in pharmaceutical research has emerged in recent years, and its utility has gone beyond bioactivity predictions and has shown promise in addressing diverse problems in drug discovery. Examples will be discussed covering bioactivity prediction, de novo molecular design, synthesis prediction and biological image analysis."
}

@book{perceptrons,
author = {Minsky, Marvin and Papert, Seymour A.},
title = {Perceptrons: An Introduction to Computational Geometry},
year = {2017},
isbn = {0262534770},
publisher = {The MIT Press},
abstract = {The first systematic study of parallelism in computation by two pioneers in the field. Reissue of the 1988 Expanded Edition with a new foreword by Lon Bottou In 1969, ten years after the discovery of the perceptron -- which showed that a machine could be taught to perform certain tasks using examples -- Marvin Minsky and Seymour Papert published Perceptrons, their analysis of the computational capabilities of perceptrons for specific tasks. As Lon Bottou writes in his foreword to this edition, "Their rigorous work and brilliant technique does not make the perceptron look very good." Perhaps as a result, research turned away from the perceptron. Then the pendulum swung back, and machine learning became the fastest-growing field in computer science. Minsky and Papert's insistence on its theoretical foundations is newly relevant. Perceptrons -- the first systematic study of parallelism in computation -- marked a historic turn in artificial intelligence, returning to the idea that intelligence might emerge from the activity of networks of neuron-like entities. Minsky and Papert provided mathematical analysis that showed the limitations of a class of computing machines that could be considered as models of the brain. Minsky and Papert added a new chapter in 1987 in which they discuss the state of parallel computers, and note a central theoretical challenge: reaching a deeper understanding of how "objects" or "agents" with individuality can emerge in a network. Progress in this area would link connectionism with what the authors have called "society theories of mind."}
}

@inbook{turing49,
author = {Turing, A.},
title = {Checking a Large Routine},
year = {1989},
isbn = {0262231360},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {The Early British Computer Conferences},
pages = {70–72},
numpages = {3}
}
@article{Consel98,
  title={Tempo: Specializing systems applications and beyond},
  author={Consel, Charles and Hornof, Luke and Marlet, Renaud and Muller, Gilles and Thibault, Scott and Volanschi, E-N and Lawall, Julia and Noy{\'e}, Jacques},
  journal={ACM Computing Surveys},
  volume={30},
  number={3es},
  year={1998},
  publisher={ACM}
}

@phdthesis{Andersen94,
  title={Program analysis and specialization for the C programming language},
  author={Andersen, Lars Ole},
  year={1994},
  school={University of Copenhagen}
}

@inproceedings{occam,
  author    = {Gregory Malecha and
               Ashish Gehani and
               Natarajan Shankar},
  title     = {Automated software winnowing},
  booktitle = {{SAC}},
  pages     = {1504--1511},
  year      = {2015},
}

@TechReport{llpe,
  author =	 {Smowton, Christopher S.F.},
  title = 	 {{I/O Optimisation and elimination via partial evaluation}},
  year = 	 2014,
  month = 	 dec,
  url = 	 {https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-865.pdf},
  institution =  {University of Cambridge, Computer Laboratory},
  issn = 	 {1476-2986},
  number = 	 {UCAM-CL-TR-865}
}

@inproceedings{trimmer,
 author = {Sharif, Hashim and Abubakar, Muhammad and Gehani, Ashish and Zaffar, Fareed},
 title = {TRIMMER: Application Specialization for Code Debloating},
 booktitle = {{ASE}},
 year = {2018},
 pages = {329--339},
}

@inproceedings{chisel,
 author = {Heo, Kihong and Lee, Woosuk and Pashakhanloo, Pardis and Naik, Mayur},
 title = {Effective Program Debloating via Reinforcement Learning},
 booktitle = {{CCS}},
 year = {2018},
 pages = {380--394},
}

@article{mix,
  author    = {Neil D. Jones and
               Peter Sestoft and
               Harald S{\o}ndergaard},
  title     = {Mix: {A} Self-Applicable Partial Evaluator for Experiments in Compiler
               Generation},
  journal   = {Lisp and Symbolic Computation},
  volume    = {2},
  number    = {1},
  pages     = {9--50},
  year      = {1989},
}

@book{pe-book,
  author    = {Neil D. Jones and
               Carsten K. Gomard and
               Peter Sestoft},
  title     = {Partial evaluation and automatic program generation},
  series    = {Prentice Hall international series in computer science},
  publisher = {Prentice Hall},
  year      = {1993},
  isbn      = {978-0-13-020249-9},
}


@inproceedings{llvm,
 author = {Lattner, Chris and Adve, Vikram},
 title = {LLVM: A Compilation Framework for Lifelong Program Analysis \& Transformation},
 booktitle = {{CGO}},
 year = {2004},
 pages = {75--},
} 

@inproceedings{piecewise,
  author    = {Anh Quach and
               Aravind Prakash and
               Lok{-}Kwong Yan},
  title     = {Debloating Software through Piece-Wise Compilation and Loading},
  booktitle = {{USENIX} Security Symposium},
  pages     = {869--886},
  year      = {2018},
}

@article{autotuning,
  author    = {Amir H. Ashouri and
               William Killian and
               John Cavazos and
               Gianluca Palermo and
               Cristina Silvano},
  title     = {A Survey on Compiler Autotuning using Machine Learning},
  journal   = {{ACM} Comput. Surv.},
  volume    = {51},
  number    = {5},
  pages     = {96:1--96:42},
  year      = {2019},
}

@inproceedings{KulkarniCWS13,
  author    = {Sameer Kulkarni and
               John Cavazos and
               Christian Wimmer and
               Doug Simon},
  title     = {Automatic construction of inlining heuristics using machine learning},
  booktitle = {{CGO}},
  pages     = {9:1--9:12},
  year      = {2013},
}

@article{code2vec,
  author    = {Uri Alon and
               Meital Zilberstein and
               Omer Levy and
               Eran Yahav},
  title     = {code2vec: learning distributed representations of code},
  booktitle = {{POPL}},
  pages     = {40:1--40:29},
  year      = {2019},
}

@inproceedings {homescu,
title = {Microgadgets: Size Does Matter in Turing-Complete Return-Oriented Programming},
booktitle = {Presented as part of the 6th {USENIX} Workshop on Offensive Technologies},
year = {2012},
address = {Bellevue, WA},
url = {https://www.usenix.org/conference/woot12/workshop-program/presentation/Homescu},
publisher = {{USENIX}},
}

@inproceedings {gsa,
author = {Michael D. Brown and Santosh Pande},
title = {Is Less Really More? Towards Better Metrics for Measuring Security Improvements Realized Through Software Debloating},
booktitle = {12th {USENIX} Workshop on Cyber Security Experimentation and Test ({CSET} 19)},
year = {2019},
address = {Santa Clara, CA},
url = {https://www.usenix.org/conference/cset19/presentation/brown},
publisher = {{USENIX} Association},
month = aug,
}

@inproceedings{pytorch,
  title={Automatic Differentiation in {PyTorch}},
  author={Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
  booktitle={NIPS Autodiff Workshop},
  year={2017}
}

@article{reinforce,
 author = {Williams, Ronald J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Mach. Learn.},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 issn = {0885-6125},
 pages = {229--256},
 numpages = {28},
 url = {https://doi.org/10.1007/BF00992696},
 doi = {10.1007/BF00992696},
 acmid = {139614},
 publisher = {Kluwer Academic Publishers},
 address = {Norwell, MA, USA},
 keywords = {Reinforcement learning, connectionist networks, gradient descent, mathematical analysis},
} 

@inproceedings{deepq,
author = {Hasselt, Hado van and Guez, Arthur and Silver, David},
title = {Deep Reinforcement Learning with Double Q-Learning},
year = {2016},
publisher = {AAAI Press},
abstract = {The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent DQN algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the DQN algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.},
booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence},
pages = {2094–2100},
numpages = {7},
location = {Phoenix, Arizona},
series = {AAAI'16}
}

@inproceedings{Schulmanetal_ICLR2016,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
year  = 2016
}

@inproceedings{adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Thu, 25 Jul 2019 14:25:37 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KingmaB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{inst2vec,
  author    = {Tal Ben{-}Nun and
               Alice Shoshana Jakobovits and
               Torsten Hoefler},
  title     = {Neural Code Comprehension: {A} Learnable Representation of Code Semantics},
  journal   = {CoRR},
  volume    = {abs/1806.07336},
  year      = {2018},
  url       = {http://arxiv.org/abs/1806.07336},
  archivePrefix = {arXiv},
  eprint    = {1806.07336},
  timestamp = {Mon, 13 Aug 2018 16:45:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1806-07336},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{code2seq,
  author    = {Uri Alon and
               Omer Levy and
               Eran Yahav},
  title     = {code2seq: Generating Sequences from Structured Representations of
               Code},
  journal   = {CoRR},
  volume    = {abs/1808.01400},
  year      = {2018},
  url       = {http://arxiv.org/abs/1808.01400},
  archivePrefix = {arXiv},
  eprint    = {1808.01400},
  timestamp = {Sun, 02 Sep 2018 15:01:56 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1808-01400},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{code2blah,
  author    = {Zimin Chen and
               Martin Monperrus},
  title     = {A Literature Study of Embeddings on Source Code},
  journal   = {CoRR},
  volume    = {abs/1904.03061},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.03061},
  archivePrefix = {arXiv},
  eprint    = {1904.03061},
  timestamp = {Wed, 24 Apr 2019 12:21:25 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1904-03061},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@INPROCEEDINGS{deeptune,
author={C. {Cummins} and P. {Petoumenos} and Z. {Wang} and H. {Leather}},
booktitle={2017 26th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
title={End-to-End Deep Learning of Optimization Heuristics},
year={2017},
volume={},
number={},
pages={219-232},
keywords={learning (artificial intelligence);multi-threading;neural nets;deepneural network;needfor manual feature creation;neural nets;optimization problem;human experts;deep learning;accurate automatic optimization heuristics;machine learning;expert domain knowledge;end-to-end deep learning;GPU threadcoarsening factors;Optimization;Feature extraction;Vocabulary;Predictive models;Neural networks;Runtime;Optimization Heuristics;Machine Learning;Compiler Optimizations;Heterogeneous Systems},
doi={10.1109/PACT.2017.24},
ISSN={},
month={Sep.},}
@article{lstm,
author = {Hochreiter, Sepp and Schmidhuber, J\"{u}rgen},
title = {Long Short-Term Memory},
year = {1997},
issue_date = {November 15, 1997},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {9},
number = {8},
issn = {0899-7667},
url = {https://doi.org/10.1162/neco.1997.9.8.1735},
doi = {10.1162/neco.1997.9.8.1735},
abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
journal = {Neural Comput.},
month = nov,
pages = {1735–1780},
numpages = {46}
}
@article{gru,
  author    = {Kyunghyun Cho and
               Bart van Merrienboer and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               Fethi Bougares and
               Holger Schwenk and
               Yoshua Bengio},
  title     = {Learning Phrase Representations using {RNN} Encoder-Decoder for Statistical
               Machine Translation},
  journal   = {CoRR},
  volume    = {abs/1406.1078},
  year      = {2014},
  url       = {http://arxiv.org/abs/1406.1078},
  archivePrefix = {arXiv},
  eprint    = {1406.1078},
  timestamp = {Mon, 13 Aug 2018 16:46:44 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ChoMGBSB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{creduce,
  author    = {John Regehr and
               Yang Chen and
               Pascal Cuoq and
               Eric Eide and
               Chucky Ellison and
               Xuejun Yang},
  title     = {Test-case reduction for {C} compiler bugs},
  booktitle = {{PLDI}},
  pages     = {335--346},
  year      = {2012},
}

@inproceedings{relu,
 author = {Nair, Vinod and Hinton, Geoffrey E.},
 title = {Rectified Linear Units Improve Restricted Boltzmann Machines},
 booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
 series = {ICML'10},
 year = {2010},
 isbn = {978-1-60558-907-7},
 location = {Haifa, Israel},
 pages = {807--814},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=3104322.3104425},
 acmid = {3104425},
 publisher = {Omnipress},
 address = {USA},
} 
@article{ling_redundancy,
  title={What is linguistic redundancy},
  author={Wit, Ernst-Jan C and Gillette, Marie},
  year={1999},
  publisher={Citeseer}
}



@misc{lample2019deep,
    title={Deep Learning for Symbolic Mathematics},
    author={Guillaume Lample and François Charton},
    year={2019},
    eprint={1912.01412},
    archivePrefix={arXiv},
    primaryClass={cs.SC}
}
@inproceedings{alphago,
author = {Holcomb, Sean D. and Porter, William K. and Ault, Shaun V. and Mao, Guifen and Wang, Jin},
title = {Overview on DeepMind and Its AlphaGo Zero AI},
year = {2018},
isbn = {9781450363587},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3206157.3206174},
doi = {10.1145/3206157.3206174},
abstract = {The goal of this paper is to give insight into what the company known as DeepMind is and what accomplishments it is making in the fields of Machine Learning and Artificial Intelligence. Among their accomplishments, particular focus will be placed upon the recent success of AlphaGo Zero which made waves in the machine learning and artificial intelligence communities. The various parts of AlphaGo Zero's implementation such as reinforcement learning, neural networks, and Monte Carlo Tree Searches will be explained with brevity to give better understanding of the process as a whole.},
booktitle = {Proceedings of the 2018 International Conference on Big Data and Education},
pages = {67–71},
numpages = {5},
keywords = {AlphaGo Zero, Deep Mind, AI, Deep Learning, Reinforcement Learning, Neural Networks},
location = {Honolulu, HI, USA},
series = {ICBDE '18}
}
@article{dropout,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
year = {2014},
issue_date = {January 2014},
publisher = {JMLR.org},
volume = {15},
number = {1},
issn = {1532-4435},
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different "thinned" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {1929–1958},
numpages = {30},
keywords = {regularization, neural networks, deep learning, model combination}
}
@misc{convai,
      title={Learning to Manipulate Deformable Objects without Demonstrations}, 
      author={Yilin Wu and Wilson Yan and Thanard Kurutach and Lerrel Pinto and Pieter Abbeel},
      year={2020},
      eprint={1910.13439},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}
@article{Nham:nips19,
    title={Reinforcement Learning Guided Software Debloating},
    author={Nham Le and Ashish Gehani and Arie Gurfinkel and Susmit Jha and Jorge A Navas},
    year={2019},
  maintitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019},
  booktitle = {Workshop on ML for Systems},
  url = {http://mlforsystems.org/assets/papers/neurips2019/reinforcement_le_van_2019.pdf}
}

@misc{CHC-COMP-18,
 title = {Constrained Horn Clauses (CHC) Competition},
 year = 2018,
 url = {https://chc-comp.github.io/}
}
@misc{glue-bench,
 title = {GLUE benchmark leaderboard},
 year = 2020,
 url = {https://gluebenchmark.com/leaderboard/}
}
@article{parallel,
  added-at = {2016-01-18T15:13:04.000+0100},
  address = {Frederiksberg, Denmark},
  author = {Tange, O.},
  journal = {;login: The USENIX Magazine},
  keywords = {imported},
  month = Feb,
  number = 1,
  OPTpages = {42-47},
  title = {{GNU Parallel -- The Command-Line Power Tool}},
  OPTurl = {http://www.gnu.org/s/parallel},
  volume = 36,
  year = 2011
}

@inproceedings{z3,
  author    = {Leonardo Mendon{\c{c}}a de Moura and
               Nikolaj Bj{\o}rner},
  OPTeditor    = {C. R. Ramakrishnan and
               Jakob Rehof},
  title     = {{Z3:} An Efficient {SMT} Solver},
  booktitle = {TACAS},
  OPTpages     = {337--340},
  OPTpublisher = {Springer},
  year      = {2008},
  OPTurl       = {https://doi.org/10.1007/978-3-540-78800-3\_24},
  OPTdoi       = {10.1007/978-3-540-78800-3\_24},
  timestamp = {Tue, 14 May 2019 10:00:53 +0200},
  biburl    = {https://dblp.org/rec/conf/tacas/MouraB08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{bert,
  author    = {Kevin Clark and
               Urvashi Khandelwal and
               Omer Levy and
               Christopher D. Manning},
  title     = {What Does {BERT} Look At? An Analysis of BERT's Attention},
  journal   = {CoRR},
  volume    = {abs/1906.04341},
  year      = {2019},
  OTPurl       = {http://arxiv.org/abs/1906.04341},
  archivePrefix = {arXiv},
  eprint    = {1906.04341},
  timestamp = {Fri, 14 Jun 2019 09:38:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-04341.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@MISC{smt2standard,
  author =	 {Clark Barrett and Pascal Fontaine and Cesare Tinelli},
  title =	 {{The Satisfiability Modulo Theories Library (SMT-LIB)}},
  howpublished = {{\tt www.SMT-LIB.org}},
  year =	 2016,
}

@inproceedings{word2vec,
  author    = {Tomas Mikolov and
               Ilya Sutskever and
               Kai Chen and
               Gregory S. Corrado and
               Jeffrey Dean},
  OPTeditor    = {Christopher J. C. Burges and
               L{\'{e}}on Bottou and
               Zoubin Ghahramani and
               Kilian Q. Weinberger},
  title     = {Distributed Representations of Words and Phrases and their Compositionality},
  booktitle = {Advances in Neural Information Processing Systems 26: 27th Annual
               Conference on Neural Information Processing Systems 2013. Proceedings
               of a meeting held December 5-8, 2013, Lake Tahoe, Nevada, United States},
  OPTpages     = {3111--3119},
  year      = {2013},
  url       = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality},
  timestamp = {Fri, 06 Mar 2020 17:00:12 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/MikolovSCCD13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {EMNLP},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  OPTpages = {1532--1543},
  OPTurl = {http://www.aclweb.org/anthology/D14-1162},
}

@inproceedings{TreeLSTM,
  author    = {Kai Sheng Tai and
               Richard Socher and
               Christopher D. Manning},
  title     = {Improved Semantic Representations From Tree-Structured Long Short-Term
               Memory Networks},
  booktitle = {ACL},
  OPTpages     = {1556--1566},
  OPTpublisher = {The Association for Computer Linguistics},
  year      = {2015},
}

@inproceedings{Allamanis:icml17,
  author    = {Miltiadis Allamanis and
               Pankajan Chanthirasegaran and
               Pushmeet Kohli and
               Charles A. Sutton},
  OPTeditor    = {Doina Precup and
               Yee Whye Teh},
  title     = {Learning Continuous Semantic Representations of Symbolic Expressions},
  booktitle = {ICML 2017},
  OPTseries    = {Proceedings of Machine Learning Research},
  volume    = {70},
  OPTpages     = {80--88},
  OPTpublisher = {{PMLR}},
  year      = {2017},
}

@inproceedings{SMC96,
  author    = {Edmund M. Clarke and
               Kenneth L. McMillan and
               S{\'{e}}rgio Vale Aguiar Campos and
               Vasiliki Hartonas{-}Garmhausen},
  OPTeditor    = {Rajeev Alur and
               Thomas A. Henzinger},
  title     = {Symbolic Model Checking},
  booktitle = {CAV},
  OPTpages     = {419--427},
  OPTpublisher = {Springer},
  year      = {1996},
}

@inproceedings{Katz:cav19,
  author    = {Guy Katz and
               Derek A. Huang and
               Duligur Ibeling and
               Kyle Julian and
               Christopher Lazarus and
               Rachel Lim and
               Parth Shah and
               Shantanu Thakoor and
               Haoze Wu and
               Aleksandar Zeljic and
               David L. Dill and
               Mykel J. Kochenderfer and
               Clark W. Barrett},
  OPTeditor    = {Isil Dillig and
               Serdar Tasiran},
  title     = {The Marabou Framework for Verification and Analysis of Deep Neural
               Networks},
  booktitle = {CAV},
  OPTpages     = {443--452},
  OPTpublisher = {Springer},
  year      = {2019},
}


@inproceedings{SeaHorn,
  author    = {Arie Gurfinkel and
               Temesghen Kahsai and
               Anvesh Komuravelli and
               Jorge A. Navas},
  OPTeditor    = {Daniel Kroening and
               Corina S. Pasareanu},
  title     = {The SeaHorn Verification Framework},
  booktitle = {CAV},
  OPTpages     = {343--361},
  OPTpublisher = {Springer},
  year      = {2015},
}

@inproceedings{GSpacer,
  author    = {Hari Govind Vediramana Krishnan and
               YuTing Chen and
               Sharon Shoham and
               Arie Gurfinkel},
  OPTeditor    = {Shuvendu K. Lahiri and
               Chao Wang},
  title     = {Global Guidance for Local Generalization in Model Checking},
  booktitle = {CAV},
  OPTpages     = {101--125},
  OPTpublisher = {Springer},
  year      = {2020},
}

@inproceedings{Sheyner:SP02,
  author    = {Oleg Sheyner and
               Joshua W. Haines and
               Somesh Jha and
               Richard Lippmann and
               Jeannette M. Wing},
  title     = {Automated Generation and Analysis of Attack Graphs},
  booktitle = {SSP},
  OPTpages     = {273--284},
  OPTpublisher = {{IEEE} Computer Society},
  year      = {2002},
}

@inproceedings{ESC-java-02,
author = {Flanagan, Cormac and Leino, K. Rustan M. and Lillibridge, Mark and Nelson, Greg and Saxe, James B. and Stata, Raymie},
title = {Extended Static Checking for Java},
year = {2002},
isbn = {1581134630},
OPTpublisher = {Association for Computing Machinery},
OPTaddress = {New York, NY, USA},
OPTurl = {https://doi.org/10.1145/512529.512558},
OPTdoi = {10.1145/512529.512558},
booktitle = {PLDI},
OPTpages = {234–245},
}

@inproceedings{Ball02,
  author    = {Thomas Ball},
  OPTeditor    = {Juan Jos{\'{e}} Moreno{-}Navarro and
               Julio Mari{\~{n}}o{-}Carballo},
  title     = {Secrets of Software Model Checking},
  booktitle = {{AGP} 2002},
  OPTpublisher = {Facultad de Inform{\'{a}}tica, Universidad Polit{\'{e}}cnica
               de Madrid},
  year      = {2002},

}

@ARTICLE{Barnat:biology12,
  author={J. {Barnat} and L. {Brim} and A. {Krejci} and A. {Streck} and D. {Safranek} and M. {Vejnar} and T. {Vejpustek}},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={On Parameter Synthesis by Parallel Model Checking}, 
  year={2012},
  volume={9},
  number={3},
  OPTpages={693-705},}
  
  @inproceedings{IC3,
  author    = {Aaron R. Bradley},
  OPTeditor    = {Ranjit Jhala and
               David A. Schmidt},
  title     = {SAT-Based Model Checking without Unrolling},
  booktitle = {VMCAI},
  OPTvolume    = {6538},
  OPTpages     = {70--87},
  OPTpublisher = {Springer},
  year      = {2011},
}

@inproceedings{Bradley:fmcad11,
  author    = {Aaron R. Bradley and
               Fabio Somenzi and
               Zyad Hassan and
               Yan Zhang},
  OPTeditor    = {Per Bjesse and
               Anna Slobodov{\'{a}}},
  title     = {An incremental approach to model checking progress properties},
  booktitle = {FMCAD},
  OPTpages     = {144--153},
  OPTpublisher = {{FMCAD} Inc.},
  year      = {2011},
}

@article{Griggio:CAD16,
  author    = {Alberto Griggio and
               Marco Roveri},
  title     = {Comparing Different Variants of the ic3 Algorithm for Hardware Model
               Checking},
  journal   = {{IEEE} Trans. on {CAD} of Integrated Circuits and Systems},
  volume    = {35},
  number    = {6},
  OPTpages     = {1026--1039},
  year      = {2016},
}

@inproceedings{PDR,
author = {Een, Niklas and Mishchenko, Alan and Brayton, Robert},
title = {Efficient Implementation of Property Directed Reachability},
year = {2011},
isbn = {9780983567813},
publisher = {FMCAD Inc},
address = {Austin, Texas},
booktitle = {Proceedings of the International Conference on Formal Methods in Computer-Aided Design},
pages = {125–134},
numpages = {10},
location = {Austin, Texas},
series = {FMCAD '11}
}

@article{BMC,
  author    = {Edmund M. Clarke and
               Armin Biere and
               Richard Raimi and
               Yunshan Zhu},
  title     = {Bounded Model Checking Using Satisfiability Solving},
  journal   = {Formal Methods Syst. Des.},
  volume    = {19},
  number    = {1},
  OPTpages     = {7--34},
  year      = {2001},
}

@article{BDD,
  author    = {Randal E. Bryant},
  title     = {Graph-Based Algorithms for Boolean Function Manipulation},
  journal   = {{IEEE} Trans. Computers},
  volume    = {35},
  number    = {8},
  OPTpages     = {677--691},
  year      = {1986},
}

@inproceedings{minisat,
  author    = {Niklas E{\'{e}}n and
               Niklas S{\"{o}}rensson},
  OPTeditor    = {Enrico Giunchiglia and
               Armando Tacchella},
  title     = {An Extensible SAT-solver},
  booktitle = {SAT},
  OPTpages     = {502--518},
  OPTpublisher = {Springer},
  year      = {2003},
}

@inproceedings{chaff,
  author    = {Matthew W. Moskewicz and
               Conor F. Madigan and
               Ying Zhao and
               Lintao Zhang and
               Sharad Malik},
  title     = {Chaff: Engineering an Efficient {SAT} Solver},
  booktitle = {DAC},
  OPTpages     = {530--535},
  OPTpublisher = {{ACM}},
  year      = {2001},
}

@inproceedings{CDCL,
  author    = {Jo{\~{a}}o P. Marques Silva and Karem A. Sakallah},
  OPTeditor    = {Rob A. Rutenbar and
               Ralph H. J. M. Otten},
  title     = {{GRASP} -- a new search algorithm for satisfiability},
  booktitle = {ICCAD},
  OPTpages     = {220--227},
  OPTpublisher = {{IEEE} Computer Society / {ACM}},
  year      = {1996},
}


@inproceedings{CEGAR,
  author    = {Edmund M. Clarke and
               Orna Grumberg and
               Somesh Jha and
               Yuan Lu and
               Helmut Veith},
  OPTeditor    = {E. Allen Emerson and
               A. Prasad Sistla},
  title     = {Counterexample-Guided Abstraction Refinement},
  booktitle = {CAV},
  OPTpages     = {154--169},
  OPTpublisher = {Springer},
  year      = {2000},
}

@inproceedings{McMillan:cav06,
  author    = {Kenneth L. McMillan},
  OPTeditor    = {Thomas Ball and
               Robert B. Jones},
  title     = {Lazy Abstraction with Interpolants},
  booktitle = {CAV},
  OPTpages     = {123--136},
  OPTpublisher = {Springer},
  year      = {2006},
}

@inproceedings{DBLP:conf/birthday/BjornerGMR15,
  author    = {Nikolaj Bj{\o}rner and
               Arie Gurfinkel and
               Kenneth L. McMillan and
               Andrey Rybalchenko},
  title     = {Horn Clause Solvers for Program Verification},
  booktitle = {Gurevich~75},
  year      = {2015},
  OPTurl       = {https://doi.org/10.1007/978-3-319-23534-9\_2},
  OPTdoi       = {10.1007/978-3-319-23534-9\_2},
  timestamp = {Tue, 14 May 2019 10:00:52 +0200},
  biburl    = {https://dblp.org/rec/conf/birthday/BjornerGMR15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{GPDR,
  author    = {Krystof Hoder and
               Nikolaj Bj{\o}rner},
  OPTeditor    = {Alessandro Cimatti and
               Roberto Sebastiani},
  title     = {Generalized Property Directed Reachability},
  booktitle = {SAT},
  volume    = {7317},
  OPTpages     = {157--171},
  OPTpublisher = {Springer},
  year      = {2012},
  OPTurl       = {https://doi.org/10.1007/978-3-642-31612-8\_13},
  OPTdoi       = {10.1007/978-3-642-31612-8\_13},
  timestamp = {Sun, 02 Jun 2019 21:24:00 +0200},
  biburl    = {https://dblp.org/rec/conf/sat/HoderB12.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{spacer,
  author    = {Anvesh Komuravelli and
               Arie Gurfinkel and
               Sagar Chaki},
  title     = {SMT-Based Model Checking for Recursive Programs},
  booktitle = {CAV},
  OPTpages     = {17--34},
  year      = {2014},
  OPTcrossref  = {DBLP:conf/cav/2014},
  OPTurl       = {https://doi.org/10.1007/978-3-319-08867-9\_2},
  OPTdoi       = {10.1007/978-3-319-08867-9\_2},
  timestamp = {Tue, 14 May 2019 10:00:43 +0200},
  biburl    = {https://dblp.org/rec/conf/cav/KomuravelliGC14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@inproceedings{Komuravelli:cav13,
  author    = {Anvesh Komuravelli and
               Arie Gurfinkel and
               Sagar Chaki and
               Edmund M. Clarke},
  OPTeditor    = {Natasha Sharygina and
               Helmut Veith},
  title     = {Automatic Abstraction in SMT-Based Unbounded Software Model Checking},
  booktitle = {CAV},
  OPTpages     = {846--862},
  OPTpublisher = {Springer},
  year      = {2013},
}


@inproceedings{Krizhevsky:nips12,
  author    = {Alex Krizhevsky and
               Ilya Sutskever and
               Geoffrey E. Hinton},
  OPTeditor    = {Peter L. Bartlett and
               Fernando C. N. Pereira and
               Christopher J. C. Burges and
               L{\'{e}}on Bottou and
               Kilian Q. Weinberger},
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  booktitle = {NeurIPS},
  OPTpages     = {1106--1114},
  year      = {2012},
}

@inproceedings{Mikolov:nips13,
  author    = {Tomas Mikolov and
               Ilya Sutskever and
               Kai Chen and
               Gregory S. Corrado and
               Jeffrey Dean},
  OPTeditor    = {Christopher J. C. Burges and
               L{\'{e}}on Bottou and
               Zoubin Ghahramani and
               Kilian Q. Weinberger},
  title     = {Distributed Representations of Words and Phrases and their Compositionality},
  booktitle = {NeurIPS},
  OPTpages     = {3111--3119},
  year      = {2013},
}

@article{ir2vec,
  author    = {Venkata Keerthy S and
               Rohit Aggarwal and
               Shalini Jain and
               Maunendra Sankar Desarkar and
               Ramakrishna Upadrasta and
               Y. N. Srikant},
  title     = {IR2Vec: {A} Flow Analysis based Scalable Infrastructure for Program
               Encodings},
  journal   = {CoRR},
  volume    = {abs/1909.06228},
  year      = {2019},
  OPTurl       = {http://arxiv.org/abs/1909.06228},
  archivePrefix = {arXiv},
  eprint    = {1909.06228},
  timestamp = {Tue, 24 Sep 2019 17:21:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-06228.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{td-gammon,
author = {Tesauro, Gerald},
title = {Temporal Difference Learning and TD-Gammon},
year = {1995},
issue_date = {March 1995},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {38},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/203330.203343},
doi = {10.1145/203330.203343},
abstract = {Ever since the days of Shannon's proposal for a chess-playing algorithm [12] and Samuel's checkers-learning program [10] the domain of complex board games such as Go, chess, checkers, Othello, and backgammon has been widely regarded as an ideal testing ground for exploring a variety of concepts and approaches in artificial intelligence and machine learning. Such board games offer the challenge of tremendous complexity and sophistication required to play at expert level. At the same time, the problem inputs and performance measures are clear-cut and well defined, and the game environment is readily automated in that it is easy to simulate the board, the rules of legal play, and the rules regarding when the game is over and determining the outcome.},
journal = {Commun. ACM},
month = mar,
pages = {58–68},
numpages = {11}
}

@article{seq2seq,
  author    = {Ilya Sutskever and
               Oriol Vinyals and
               Quoc V. Le},
  title     = {Sequence to Sequence Learning with Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1409.3215},
  year      = {2014},
  OPTurl       = {http://arxiv.org/abs/1409.3215},
  archivePrefix = {arXiv},
  eprint    = {1409.3215},
  timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SutskeverVL14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Si:nips18,
  author    = {Xujie Si and
               Hanjun Dai and
               Mukund Raghothaman and
               Mayur Naik and
               Le Song},
  OPTeditor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {Learning Loop Invariants for Program Verification},
  booktitle = {NeurIPS},
  OPTpages     = {7762--7773},
  year      = {2018},

}

@inproceedings{Balunovic:nips18,
  author    = {Mislav Balunovic and
               Pavol Bielik and
               Martin T. Vechev},
  OPTeditor    = {Samy Bengio and
               Hanna M. Wallach and
               Hugo Larochelle and
               Kristen Grauman and
               Nicol{\`{o}} Cesa{-}Bianchi and
               Roman Garnett},
  title     = {{Learning to Solve {SMT} Formulas}},
  booktitle = {NeurIPS},
  year      = {2018},
  OPTurl       = {http://papers.nips.cc/paper/8233-learning-to-solve-smt-formulas},
  timestamp = {Fri, 06 Mar 2020 17:00:31 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/BalunovicBV18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Ryan:iclr20,
  author    = {Gabriel Ryan and
               Justin Wong and
               Jianan Yao and
               Ronghui Gu and
               Suman Jana},
  title     = {{CLN2INV:} Learning Loop Invariants with Continuous Logic Networks},
  booktitle = {8th International Conference on Learning Representations, {ICLR} 2020,
               Addis Ababa, Ethiopia, April 26-30, 2020},
  OPTpublisher = {OpenReview.net},
  year      = {2020},
}

@inproceedings{He:pldi20,
  author    = {Jingxuan He and
               Gagandeep Singh and
               Markus P{\"{u}}schel and
               Martin T. Vechev},
  OPTeditor    = {Alastair F. Donaldson and
               Emina Torlak},
  title     = {Learning fast and precise numerical analysis},
  booktitle = {PLDI},
  OPTpages     = {1112--1127},
  OPTpublisher = {{ACM}},
  year      = {2020},
}

@inproceedings{Evans:iclr18,
  author    = {Richard Evans and
               David Saxton and
               David Amos and
               Pushmeet Kohli and
               Edward Grefenstette},
  title     = {Can Neural Networks Understand Logical Entailment?},
  booktitle = {ICLR},
  OPTpublisher = {OpenReview.net},
  year      = {2018},
}

@article{DeepProbLog,
  author    = {Robin Manhaeve and
               Sebastijan Dumancic and
               Angelika Kimmig and
               Thomas Demeester and
               Luc De Raedt},
  title     = {DeepProbLog: Neural Probabilistic Logic Programming},
  journal   = {CoRR},
  volume    = {abs/1907.08194},
  year      = {2019},
}

@inproceedings{DBLP:conf/iclr/SelsamLBLMD19,
  author    = {Daniel Selsam and
               Matthew Lamm and
               Benedikt B{\"{u}}nz and
               Percy Liang and
               Leonardo de Moura and
               David L. Dill},
  title     = {{Learning a {SAT} Solver from Single-Bit Supervision}},
  booktitle = {ICLR},
  year      = {2019},
  OPTcrossref  = {DBLP:conf/iclr/2019},
  OPTurl       = {https://openreview.net/forum?id=HJMC\_iA5tm},
  timestamp = {Thu, 25 Jul 2019 14:25:49 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/SelsamLBLMD19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{DBLP:conf/sat/SelsamB19,
  author    = {Daniel Selsam and
               Nikolaj Bj{\o}rner},
  title     = {{Guiding High-Performance {SAT} Solvers with Unsat-Core Predictions}},
  booktitle = {SAT},
  OPTpages     = {336--353},
  year      = {2019},
  OPTcrossref  = {DBLP:conf/sat/2019},
  OPTurl       = {https://doi.org/10.1007/978-3-030-24258-9\_24},
  OPTdoi       = {10.1007/978-3-030-24258-9\_24},
  timestamp = {Mon, 01 Jul 2019 14:18:25 +0200},
  biburl    = {https://dblp.org/rec/conf/sat/SelsamB19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}