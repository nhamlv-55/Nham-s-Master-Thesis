\chapter{Future Work}
\label{chap:future}
Recent advances in deep learning, especially language modeling, has played a tremendous role in solving many natural language reasoning tasks that used to be considered infeasible. Yet, neural-guidance for symbolic reasoning is still a barely charted territory, with successes few and far between.
In previous chapters, we have studied two exciting applications of learning a better heuristic for symbolic reasoning tasks, specifically Inductive Generalization, and Software Debloating.
In this chapter, we outline some future directions on guiding symbolic reasoning using machine learning, which we think are feasible, and will play a major role in making neural-guidance not just another tool, but a powerful hammer in tackling down symbolic reasoning tasks.

\paragraph{Representation learning for formal languages.} Deep learning has made tremendous progress in understanding natural language, and in many cases surpassing human-level \cite{whosaidwhat, whosaidwhat2}. However, there is a big gap between natural language understanding and formal language understanding. Natural language, as a means of transferring information through noisy channels (i.e soundwave through the air, or word-of-mouth gossipping), has a lot of redundancy in both grammar and context \cite{ling_redundancy}. This redundancy helps with, among others, enhancing the comprehensibility of natural language. In contrast, formal languages, such as formulas or programming languages, are designed to be as concise and compact as possible, with little to no redundancy. This makes representation learning for formal languages very challenging. For example, many breakthroughs in NLP are based on the word-guessing tasks --- given a sentence, we randomly remove some words in it, and try to guess them using the remaining words --- such as word2vec \cite{word2vec} or BERT \cite{bert}. Due to redundancy, it is reasonable to try guessing a word from its context, but it is counter-intuitive to try to do the same for formal languages. 

One promising way to learn a good representation for formal languages is to use the structure of the entities. In \cref{chap:dopey}, we show that augmenting an AST with domain knowledge about the tokens can achieve good results on representing linear arithmetics formulas. Given that graph-based and tree-based methods have been successful in structure learning tasks, such as drug discovery \cite{drug_dis}, it is reasonable to believe that representation learning for small to medium mathematical formulas is feasible. While in \cref{chap:doccam}, we cannot transfer results of inst2vec \cite{inst2vec} into our domain, this graph-based work shows promising results in many different tasks, and it is foreseeable that better feature engineering at the token level may help us achieve even better code representation.

\paragraph{Transfer learning for formal languages.} 
One of the main reasons for the wide adoptation of deep learning is the success of \emph{transfer learning}. Starting from a model pretrained on millions of labeled images using hundreds of GPU hours, an individual researcher can easily fine tune it for a task that may have only a handful of training examples, using a small amount of computing power. ELMo \cite{elmo} and BERT \cite{bert} were big breakthroughs in NLP for the same reason: previously, each NLP task required a full end-to-end training, making it very difficult to use deep learning to solve NLP problems with small datasets. 

The main challenge in successful transfer learning for symbolic reasoning lies in the fact that downstream tasks are often \emph{representation specific}: while one can imagine a model trained on a dataset about the Python programming language can be helpful to do Python reasoning tasks (e.g neural-based auto-completion), there is little reason to believe it would help detect memory leaks in C++, a bug that is completely missing in Python. This is very different in natural language, where tasks for different languages are often the same: answering questions, analysing sentiments, extracting entities, among others. Because of this reason, while the amount of available code and formulas are tremendous, it is still not clear how one can train a useful general model that can be finetuned to solve multiple different tasks. 

% Nevertheless, in \cref{chap:dopey}, we have explored the possibility of transfer learning between similar problems, and recent works like \cite{lample2019deep} and \cite{neuralsat} shows that it is also feasible to learn heuristics that transfers between a more diverse set of problems in the same task. 
A useful idea that borrowed from the compilers community: at the end of the day, all programming languages have to be compiled to machine instructions. A model trained on this lowest level of abstraction, or some other forms of Intermediate Representation (IR), could be the key to the puzzle. While there is still no pre-trained model that is helpful for multiple tasks in practice, we envision that this is a solvable missing piece to make neural-guidance learning truly useful.
